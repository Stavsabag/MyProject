{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f226576-4998-4a7c-b0be-20df1e4e86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('Behavioral_data_final.csv')\n",
    "\n",
    "\n",
    "#### Downsampling\n",
    "\n",
    "df_majority = df[df['Privacy Exists']==0]\n",
    "df_minority = df[df['Privacy Exists']==1]\n",
    "\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=len(df_minority),     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "\n",
    "class0_qty = len(df_downsampled[df_downsampled['Privacy Exists'] == 0])\n",
    "class1_qty = len(df_downsampled[df_downsampled['Privacy Exists'] == 1])\n",
    "\n",
    "\n",
    "X = df_downsampled.iloc[:, 1:-1].values\n",
    "Y = df_downsampled.iloc[:, -1:].values\n",
    "\n",
    "column_names = df.columns[1:-1].tolist()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler();\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Shuffle the rows of the input and output arrays\n",
    "shuffle_idx = np.random.permutation(X.shape[0])\n",
    "X_new = X[shuffle_idx]\n",
    "Y_new = Y[shuffle_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(C=10, max_iter=100),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=5, n_estimators=200),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.01, max_depth=3, n_estimators=100),\n",
    "    'SVM': SVC(C=0.1, kernel='rbf')\n",
    "}\n",
    "\n",
    "# Define the k-fold cross-validation splitter\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# PCA\n",
    "\n",
    "df_results = pd.DataFrame(columns=[\n",
    "    'id',\n",
    "    'Class 0 quantity',\n",
    "    'Class 1 quantity',\n",
    "    'classifier',\n",
    "    'cross validation',\n",
    "    'method',\n",
    "    'number of features',\n",
    "    'variance captured',\n",
    "    'train accuracy',\n",
    "    'test accuracy'\n",
    "])\n",
    "\n",
    "# Loop over the feature numbers\n",
    "j = 0\n",
    "\n",
    "\n",
    "# Create an empty dictionary to store the PCA results\n",
    "pca_results = {}\n",
    "\n",
    "for number_of_best_feature in range(5, X_new.shape[1] + 1, 5):\n",
    "    # Apply PCA only if the PCA results are not already in the dictionary\n",
    "    if number_of_best_feature not in pca_results:\n",
    "        pca = PCA(n_components=number_of_best_feature)\n",
    "        X_pca = pca.fit_transform(X_new)\n",
    "        cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "        # Store the PCA results in the dictionary\n",
    "        pca_results[number_of_best_feature] = {\n",
    "            'X_pca': X_pca,\n",
    "            'cumulative_variance': cumulative_variance\n",
    "        }\n",
    "\n",
    "# Loop over the models and feature numbers\n",
    "for name, model in models.items():\n",
    "    for number_of_best_feature in range(5, X_new.shape[1] + 1, 5):\n",
    "        # Retrieve X_pca and cumulative_variance from the dictionary\n",
    "        pca_data = pca_results[number_of_best_feature]\n",
    "        X_pca = pca_data['X_pca']\n",
    "        cumulative_variance = pca_data['cumulative_variance']\n",
    "\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X_pca, Y_new):\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test = X_pca[train_idx], X_pca[test_idx]\n",
    "            y_train, y_test = Y_new[train_idx], Y_new[test_idx]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the training and testing sets\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            # Predict on the training and testing sets\n",
    "            y_train_pred = model.predict(X_train).reshape(-1, 1)\n",
    "            y_test_pred = model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "            # Calculate the accuracy on the training and testing sets\n",
    "            train_accuracy = accuracy_score(y_train_pred, y_train)\n",
    "            test_accuracy = accuracy_score(y_test_pred, y_test)\n",
    "\n",
    "            # Append the accuracies to the lists\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        train_accuracy_mean = np.mean(train_accuracies)\n",
    "        test_accuracy_mean = np.mean(test_accuracies)\n",
    "\n",
    "        # Add the results to the DataFrame\n",
    "        df_results = df_results.append({\n",
    "            'id': f'{j + 1:02d}',\n",
    "            'Class 0 quantity': class0_qty,\n",
    "            'Class 1 quantity': class1_qty,\n",
    "            'classifier': name,\n",
    "            'cross validation': '5-Fold',\n",
    "            'method': 'PCA',\n",
    "            'number of features': number_of_best_feature,\n",
    "            'variance captured': cumulative_variance[-1],\n",
    "            'train accuracy': train_accuracy_mean,\n",
    "            'test accuracy': test_accuracy_mean\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        j += 1\n",
    "\n",
    "        print('For model:', name)\n",
    "        print('Number of feature:', number_of_best_feature)\n",
    "        print('Train accuracy:', train_accuracy_mean)\n",
    "        print('Test accuracy:', test_accuracy_mean)\n",
    "\n",
    "# Specify the file path for saving the HTML file\n",
    "output_file_path = r'C:\\Users\\ASAF\\PycharmProjects\\pythonProject1\\results_PCA_sklearn.html'\n",
    "\n",
    "# Convert DataFrame to HTML table\n",
    "html_table = df_results.to_html(index=False)\n",
    "\n",
    "# Write HTML table to a file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(html_table)\n",
    "\n",
    "# K-best\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(columns=[\n",
    "    'id',\n",
    "    'Class 0 quantity',\n",
    "    'Class 1 quantity',\n",
    "    'classifier',\n",
    "    'cross validation',\n",
    "    'method',\n",
    "    'number of features',\n",
    "    'features_name',\n",
    "    'feature score',\n",
    "    'train accuracy',\n",
    "    'test accuracy'\n",
    "])\n",
    "\n",
    "# Loop over the feature numbers\n",
    "j = 0\n",
    "\n",
    "# Create an empty dictionary to store the feature selection results\n",
    "feature_selection_results = {}\n",
    "\n",
    "for number_of_best_feature in range(5, X_new.shape[1] + 1, 5):\n",
    "    # Apply feature selection only if the results are not already in the dictionary\n",
    "    if number_of_best_feature not in feature_selection_results:\n",
    "        selector = SelectKBest(mutual_info_classif, k=number_of_best_feature)\n",
    "\n",
    "        # Fit the selector on the training data\n",
    "        selector.fit(X_new, Y_new)\n",
    "        feature_indices = selector.get_support(indices=True)\n",
    "        feature_names = [column_names[i] for i in feature_indices]\n",
    "        feature_scores = selector.scores_\n",
    "        feature_score = feature_scores[feature_indices]\n",
    "\n",
    "        # Store the feature selection results in the dictionary\n",
    "        feature_selection_results[number_of_best_feature] = {\n",
    "            'feature_indices': feature_indices,\n",
    "            'feature_names': feature_names,\n",
    "            'feature_scores': feature_score\n",
    "        }\n",
    "\n",
    "# Loop over the models and feature numbers\n",
    "for name, model in models.items():\n",
    "    for number_of_best_feature in range(5, X_new.shape[1] + 1, 5):\n",
    "        # Retrieve feature selection results from the dictionary\n",
    "        feature_selection_data = feature_selection_results[number_of_best_feature]\n",
    "        feature_indices = feature_selection_data['feature_indices']\n",
    "        feature_names = feature_selection_data['feature_names']\n",
    "        feature_scores = feature_selection_data['feature_scores']\n",
    "\n",
    "        # Transform the training and testing data based on the selected features\n",
    "        X_selected = X_new[:, feature_indices]\n",
    "\n",
    "\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X_selected, Y_new):\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "            y_train, y_test = Y_new[train_idx], Y_new[test_idx]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the training and testing sets\n",
    "            y_train_pred = model.predict(X_train).reshape(-1, 1)\n",
    "            y_test_pred = model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "            # Calculate the accuracy on the training and testing sets\n",
    "            train_accuracy = accuracy_score(y_train_pred, y_train)\n",
    "            test_accuracy = accuracy_score(y_test_pred, y_test)\n",
    "\n",
    "            # Append the accuracies to the lists\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        train_accuracy_mean = np.mean(train_accuracies)\n",
    "        test_accuracy_mean = np.mean(test_accuracies)\n",
    "\n",
    "        # Add the results to the DataFrame\n",
    "        df_results = df_results.append({\n",
    "            'id': f'{j + 1:02d}',\n",
    "            'Class 0 quantity': class0_qty,\n",
    "            'Class 1 quantity': class1_qty,\n",
    "            'classifier': name,\n",
    "            'cross validation': '5-Fold',\n",
    "            'method': 'SelectKBest',\n",
    "            'number of features': number_of_best_feature,\n",
    "            'features_name': ', '.join(map(str, feature_names)),\n",
    "            'feature score': feature_scores,\n",
    "            'train accuracy': train_accuracy_mean,\n",
    "            'test accuracy': test_accuracy_mean\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        j += 1\n",
    "\n",
    "        print('For model:', name)\n",
    "        print('Number of feature:', number_of_best_feature)\n",
    "        print('Train accuracy:', train_accuracy_mean)\n",
    "        print('Test accuracy:', test_accuracy_mean)\n",
    "\n",
    "# Specify the file path for saving the HTML file\n",
    "output_file_path = r'C:\\Users\\ASAF\\PycharmProjects\\pythonProject1\\results_SelectKBest_sklearn_new_kfold.html'\n",
    "\n",
    "# Convert DataFrame to HTML table\n",
    "html_table = df_results.to_html(index=False)\n",
    "\n",
    "# Write HTML table to a file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(html_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
