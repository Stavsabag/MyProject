{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47508e53-bf0d-4dc4-9c34-d3426c38d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script processes privacy information in a Twitter user dataset and determines whether each user's account exists or not.\n",
    "# It connects to a SQLite database, retrieves the user IDs, and checks if each user is present or marked as not found.\n",
    "# The script then stores the existence information in a separate table in the database.\n",
    "# The script operates in chunks to handle large datasets efficiently.\n",
    "\n",
    "import sqlite3\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# connect to database\n",
    "conn = sqlite3.connect('TwitterUserChanges.db')\n",
    "conn.row_factory = sqlite3.Row\n",
    "\n",
    "# create table if not exists\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS processed_data (\n",
    "        user_id TEXT,\n",
    "        feature_name TEXT,\n",
    "        value REAL,\n",
    "        test_time TEXT,\n",
    "        UNIQUE(user_id, feature_name)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# get current time\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "feature = \"Exists\"\n",
    "\n",
    "# get distinct user IDs\n",
    "cursor = conn.execute(\"SELECT DISTINCT user_id FROM users\")\n",
    "user_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# get distinct user IDs\n",
    "cursor = conn.execute(\"SELECT DISTINCT user_id FROM user_not_found\")\n",
    "user_ids_not_found = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Define the chunk size for batch insertion\n",
    "chunk_size = len(user_ids)\n",
    "chunk_amount = len(user_ids)/chunk_size\n",
    "\n",
    "# Loop through user IDs in chunks\n",
    "for i in range(0, len(user_ids), chunk_size):\n",
    "    user_ids_chunk = user_ids[i:i+chunk_size]\n",
    "    remaining_iterations2 = chunk_size\n",
    "\n",
    "    # Create an array to store processed data for the chunk of users\n",
    "    processed_data_chunk = np.zeros((chunk_size * len(feature), 3), dtype=np.object)\n",
    "    j = 0\n",
    "\n",
    "    # Loop through each user in the chunk\n",
    "    for user_id in user_ids_chunk:\n",
    "\n",
    "        if user_id in user_ids_not_found :\n",
    "            value = 1\n",
    "        else:\n",
    "            value = 0\n",
    "\n",
    "        processed_data_chunk[j, 0] = user_id\n",
    "        processed_data_chunk[j, 1] = \"Privacy \" + feature\n",
    "        processed_data_chunk[j, 2] = value\n",
    "        j += 1\n",
    "\n",
    "        remaining_iterations2 -= 1\n",
    "        print((\"Iterations left:\", remaining_iterations2))\n",
    "\n",
    "        if j == chunk_size * len(feature) :\n",
    "            break\n",
    "\n",
    "    # Insert the chunk of data into the database\n",
    "    cursor = conn.cursor()\n",
    "    values = [(row[0], row[1], row[2], current_time) for row in processed_data_chunk if any(row)]\n",
    "    cursor.executemany(\n",
    "        \"INSERT OR REPLACE INTO processed_data (user_id, feature_name, value, test_time) VALUES (?, ?, ?, ?)\", values)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    chunk_amount -= 1\n",
    "    print(\"chunk_left:\", chunk_amount)\n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
